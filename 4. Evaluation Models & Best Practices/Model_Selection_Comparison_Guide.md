
# Model Selection: Comparison Guide

Selecting the right evaluation model depends on your instructional goals, resources, and stakeholders. This guide provides a comparison of common models to support informed decision-making.

## Evaluation Model Comparison Table

| Model                 | Focus Area                  | Strengths                                             | Ideal For                                           | Limitations                                           |
|----------------------|-----------------------------|-------------------------------------------------------|-----------------------------------------------------|-------------------------------------------------------|
| Kirkpatrick           | Learner Reaction to Results | Easy to understand, widely adopted                   | Standard training programs                          | Can be overly simplistic for complex outcomes         |
| ADDIE (Evaluation)    | Process-Oriented            | Built-in evaluation throughout design cycle           | Instructional systems design                        | Not a standalone evaluation framework                 |
| Phillips ROI          | Financial Impact            | Adds monetary return analysis                        | Programs needing financial justification            | Requires accurate cost-benefit data                   |
| CIPP                  | Context, Input, Process, Product | Comprehensive, systemic view                     | Large-scale educational initiatives                 | Can be time-intensive to implement                    |
| Brinkerhoff Success Case | Real-world success/failure | Focuses on actual application                        | Performance-driven programs                         | Less useful for general trend analysis                |

## Guidance for Model Selection

### Key Questions to Ask:
- What is the primary goal of your evaluation? (E.g., improve design, demonstrate ROI)
- Who are the stakeholders, and what data do they value most?
- Do you need formative (in-development) or summative (end-result) evaluation?
- How complex is the training/program you are evaluating?

### Model Selection Scenarios:
- **Corporate Training ROI** → Use **Phillips ROI Methodology**
- **Academic Program Review** → Use **CIPP**
- **Quick Post-Training Survey** → Use **Kirkpatrick Levels 1 & 2**
- **Instructional Design Process Review** → Use **ADDIE Evaluation**
- **Investigating Success Stories** → Use **Brinkerhoff Success Case**

Use this comparison to align your evaluation framework with instructional priorities, available data, and intended impact.

